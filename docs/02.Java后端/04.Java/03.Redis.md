---
title: Redis
date: 2020-11-16 21:36:23
permalink: /pages/ae6ab2/
categories:
  - Java后端
  - Java
tags:
  - 
---


# Redis

# 为什么要有缓冲数据库的原因

方案四,有多个服务器时 如何高效的保存session

![image-20200830010013287](https://gitee.com/claa/tuci/raw/master/img/image-20200830010013287.png)



# Redis 性能高的原因

单线程+ 多路IO复用(Linux系统)+ 访问的是内存

![image-20200830011529460](https://gitee.com/claa/tuci/raw/master/img/image-20200830011529460.png)



![image-20200830011739945](https://gitee.com/claa/tuci/raw/master/img/image-20200830011739945.png)

#  Redis 特点和安装

## Redis 概述

Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件

## Redis 特点



- 性能极高 – Redis能读的速度是10万次/s,写的速度是8万次/s 。

- 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。

  

## Redis 安装

1. [下载地址](https://redis.io/)

   ![image-20200821194011546](https://gitee.com/claa/tuci/raw/master/img/image-20200821194011546.png)

2. 在Linux 安装

   (1)放在opt 目录下

   ![image-20200821194713983](https://gitee.com/claa/tuci/raw/master/img/image-20200821194713983.png)

​       (2) 解压

```shell
tar -zxvf redis-6.0.6.tar.gz
```

​      ![image-20200821195056232](https://gitee.com/claa/tuci/raw/master/img/image-20200821195056232.png)

​      (3)安装

```shell
yum install gcc-c++

make && make install
```

[make出错解决方案](https://blog.csdn.net/realize_dream/article/details/106483499?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-5)

​     (4) redis 的默认安装路径 usr/local/bin 

![image-20200821201531793](https://gitee.com/claa/tuci/raw/master/img/image-20200821201531793.png)

​    (5)将redis 的配置 文件复制到当前目录下

```
mkdir redisconfig

cp /opt/redis-6.0.6/redis.conf  redisconfig
```

![image-20200821202217608](https://gitee.com/claa/tuci/raw/master/img/image-20200821202217608.png)



   (6)redis 默认不是后台启动的，修改配置文件

![image-20200821202724328](https://gitee.com/claa/tuci/raw/master/img/image-20200821202724328.png)



  (7) 启动redis 服务

```shell
redis-server redisconfig/redis.conf
```

![image-20200821203025007](https://gitee.com/claa/tuci/raw/master/img/image-20200821203025007.png)

  (8)测试是否可以连通

```shell
redis-cli -p 6379
```

![image-20200821203247174](https://gitee.com/claa/tuci/raw/master/img/image-20200821203247174.png)

(9) 查看redis 的进程

```shell
ps -ef|grep redis
```

![image-20200821203616993](https://gitee.com/claa/tuci/raw/master/img/image-20200821203616993.png)

(10)关闭redis 服务

```shell
shutdown

exit
```

![image-20200821203802469](https://gitee.com/claa/tuci/raw/master/img/image-20200821203802469.png)

## Redis性能测试

**redis-benchmark** 是一个压力测试工具！

官方自带的性能测试工具。

redis-benchmark 命令参数,来自菜鸟教程：

|      |           |                                            |           |
| :--- | :-------- | :----------------------------------------- | :-------- |
| 序号 | 选项      | 描述                                       | 默认值    |
| 1    | **-h**    | 指定服务器主机名                           | 127.0.0.1 |
| 2    | **-p**    | 指定服务器端口                             | 6379      |
| 3    | **-s**    | 指定服务器 socket                          |           |
| 4    | **-c**    | 指定并发连接数                             | 50        |
| 5    | **-n**    | 指定请求数                                 | 10000     |
| 6    | **-d**    | 以字节的形式指定 SET/GET 值的数据大小      | 2         |
| 7    | **-k**    | 1=keep alive 0=reconnect                   | 1         |
| 8    | **-r**    | SET/GET/INCR 使用随机 key, SADD 使用随机值 |           |
| 9    | **-P**    | 通过管道传输 <numreq> 请求                 | 1         |
| 10   | **-q**    | 强制退出 redis。仅显示 query/sec 值        |           |
| 11   | **--csv** | 以 CSV 格式输出                            |           |
| 12   | **-l**    | 生成循环，永久执行测试                     |           |
| 13   | **-t**    | 仅运行以逗号分隔的测试命令列表。           |           |
| 14   | **-I**    | Idle 模式。仅打开 N 个 idle 连接并等待。   |           |

```shell
# 测试：100个并发连接 100000请求

redis-benchmark -h localhost -p 6379 -c 100 -n 100000

```

![image-20200823104539861](https://gitee.com/claa/tuci/raw/master/img/image-20200823104539861.png)

Redis 基本知识

**Redis 默认有16个数据库**

![image-20200823111549416](https://gitee.com/claa/tuci/raw/master/img/image-20200823111549416.png)

**使用select 进行切换数据库**

```shell
select 3
```

**查看数据库所有的key**

```shell
keys *
```

**清除当前数据库**

```shell
flushdb
```

**清除全部数据的内容**

```shell
flushall
```

**Redis 是单线程的**

Redis是基于内存操作的，CPU 不是Redis 性能瓶颈，Redis的瓶颈是根据机器的的内存和网络带宽。

**Redis 为什么单线程还这么快？**

计算机 I/O 速度：CPU> 内存 > 硬盘

多线程（存在CPU上下文切换，耗费一定的时间）。

Redis 将所有的数据全部存在内存中，所以使用单线程去操作效率就是高的。



# Redis 五大数据类型

## Redis-key

 ### 查看所有的key

```shell
keys *
```

### 设置key

```shell
set name taoshe
```

### 判断当前的key 是否存在

```shell
exists name
```

### 移除当前的key

```shell
move name
```

### 设置key 的过期时间，单位是秒

```shell
expire name 10
```

### 查看当前key 的剩余时间

```shell
ttl name
```

### 查看当前key的一个类型

```shell 
type name 
```



## String(字符串)

### 追加字符串，如果当前key不存在，就相当于set Key

```shell
append name 'tao'
```

### 返回字符串的长度

```shell
strlen name 
```

### 自增1

```shell
set view 0

incr view
```

### 自减1

```shell
decr view
```

### 自增多

```shell
incrby view 10
```

### 自减多

```shell
incrby view 2
```

### 字符串范围

```shell
set key 'hello, redis world'

## 截取
getrange key 0 3

getrange key 0 -1

## 替换
setrange key 0 xx


```

 ### 设置过期时间 setex 

```shell
setex key3 30 "hello"
```

### 不存在设置 setnx

```shell
setnx mykey "redis"
```

### 批量设置(原子性)

```shell
mset K1 v1 k2 v2
```

### 批量获取

```shell
mget k1 k2
```

### 对象

```shell
set user:1 {name:zhangsan,age:3} # 设置一个user:1对象 值为json字符来保存一个对象

mest user:2:name zhangsan user:2:age 2

mget user:2:name user:2:age
```

### getset 

```shell
getset db redis # 如果值不存在，则返回nil

getset db monggodb # 如果存在值，获取原来的值，并设置新的值
```

## List(列表)

所有List的命令基本上都是L开头的

### lpush

```shell
127.0.0.1:6379> lpush list one
(integer) 1
127.0.0.1:6379> lpush list two
(integer) 2
127.0.0.1:6379> lpush list three
(integer) 3


127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "two"
3) "one"
```

### rpush

```shell
rpush list righter

127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "two"
3) "one"
4) "rigthter"
```

### lpop

```shell
127.0.0.1:6379> lpop list
"three"
127.0.0.1:6379> lrange list 0 -1
1) "two"
2) "one"
3) "rigthter"
```

### rpop

```shell
127.0.0.1:6379> rpop list
"rigthter"
127.0.0.1:6379> lrange list 0 -1
1) "two"
2) "one"
```

### lindex

```shell
127.0.0.1:6379> lindex list 0
"two"
127.0.0.1:6379> lrange list 0 -1
1) "two"
2) "one"
```

### llen

```shell
127.0.0.1:6379> llen list
(integer) 2
127.0.0.1:6379> lrange list 0 -1
1) "two"
2) "one"
```

### lrem

```shell
127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "three"
3) "two"
4) "one"
127.0.0.1:6379> lrem list 4 one
(integer) 1
127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "three"
3) "two"
127.0.0.1:6379> lrem list 2 three
(integer) 2
127.0.0.1:6379> lrange list 0 -1
1) "two"
```

ltrim

```shell
127.0.0.1:6379> rpush mylist one
(integer) 1
127.0.0.1:6379> rpush mylist one1
(integer) 2
127.0.0.1:6379> rpush mylist one2
(integer) 3
127.0.0.1:6379> rpush mylist one3
(integer) 4
127.0.0.1:6379> lrange mylist 0 -1
1) "one"
2) "one1"
3) "one2"
4) "one3"
127.0.0.1:6379> ltrim mylist 1 2
OK
127.0.0.1:6379> lrange mylist 0 -1
1) "one1"
2) "one2"
```

### rpoplpush

移除列表中最后一个元素，将它移动到新的列表中

```shell
127.0.0.1:6379> lrange mylist 0 -1
1) "one1"
2) "one2"
127.0.0.1:6379> rpoplpush mylist list
"one2"
127.0.0.1:6379> lrange mylist 0 -1
1) "one1"
127.0.0.1:6379> lrange list 0 -1
1) "one2"
2) "two"
```

### lset 

将列表中指定下标的值替换成另外一个值

```shell
127.0.0.1:6379> lset list 0 one
OK
127.0.0.1:6379> lrange list 0 -1
1) "one"
2) "two"
```

### linsert

```shell
127.0.0.1:6379> linsert list before one zero
(integer) 3
127.0.0.1:6379> lrange list 0 -1
1) "zero"
2) "one"
3) "two"
```

## Set(集合)无序不重复



### sadd

```shell
127.0.0.1:6379> sadd myset one
(integer) 1
127.0.0.1:6379> sadd myset tow
(integer) 1
127.0.0.1:6379> sadd myset three
(integer) 1
```



### smembers

```shell
127.0.0.1:6379> smembers myset
1) "tow"
2) "one"
3) "three"
```



### sismember

```shell
127.0.0.1:6379> sismember myset one
(integer) 1
```

### scard

```shell
127.0.0.1:6379> scard myset
(integer) 3
```

### srem

```shell
127.0.0.1:6379> srem myset one
(integer) 1
127.0.0.1:6379> smembers myset
1) "tow"
2) "three"
```

### srandmember

```shell
127.0.0.1:6379> srandmember myset
"three"
127.0.0.1:6379> srandmember myset
"three"
127.0.0.1:6379> srandmember myset
"three"
127.0.0.1:6379> srandmember myset
"tow"
```

### spop

随机删除一些set 集合中的元素

```shell
127.0.0.1:6379> spop myset
"tow"
127.0.0.1:6379> smembers myset
1) "three"
```

### smove

```shell
127.0.0.1:6379> smove myset myset1 three
(integer) 1
127.0.0.1:6379> smembers myset1
1) "three"
```

### 差集、交集、并集

```shell
127.0.0.1:6379> sadd key1 'a'
(integer) 1
127.0.0.1:6379> sadd key1 'b'
(integer) 1
127.0.0.1:6379> sadd key1 'c'
(integer) 1
127.0.0.1:6379> sadd key1 'd'
(integer) 1
127.0.0.1:6379> sadd key2 'a'
(integer) 1
127.0.0.1:6379> sadd key2 'b'
(integer) 1

# 差集
127.0.0.1:6379> sdiff key1 key2
1) "d"
2) "c"


# 交集
127.0.0.1:6379> sinter key1 key2
1) "b"
2) "a"

# 并集
127.0.0.1:6379> sunion key1 key2
1) "b"
2) "c"
3) "a"
4) "d"

```



## Hash

Map 集合，key-map 时候这个值是一个map 集合

### hset

```shell
127.0.0.1:6379> hset myhash key one
(integer) 1
127.0.0.1:6379> hset myhash my tow
(integer) 1

```



### hget

```shell
127.0.0.1:6379> hget myhash key
"one"
```



### hmset

```shell
127.0.0.1:6379> hset myhash key1 two key2 three
(integer) 2
```



### hmget

```shell
127.0.0.1:6379> hmget myhash key1 key2
1) "two"
2) "three"
```



### hgetall

```shell
127.0.0.1:6379> hgetall  myhash 
1) "key"
2) "one"
3) "my"
4) "tow"
5) "key1"
6) "two"
7) "key2"
8) "three"
```



### hdel

```shell
127.0.0.1:6379> hdel myhash my
(integer) 1
```

### hlen

```shell
127.0.0.1:6379> hlen myhash
(integer) 3
```

### hexists

```
127.0.0.1:6379> hexists myhash key
(integer) 1
```

### hkeys

```shell
127.0.0.1:6379> hkeys myhash
1) "key"
2) "key1"
3) "key2"
```

### hvals

```shell
127.0.0.1:6379> hvals myhash
1) "one"
2) "two"
3) "three"
```





## Zset(有序集合)

### zset

```shell
127.0.0.1:6379> zadd myset 1 one
(integer) 1
127.0.0.1:6379> zadd myset 2 two 3 three
(integer) 2
127.0.0.1:6379> zrange myset 0 -1
1) "one"
2) "two"
3) "three"
```

### 排序

```
127.0.0.1:6379> zadd salary 2500 xiaohong
(integer) 1
127.0.0.1:6379> zadd salary 5000 tao
(integer) 1
127.0.0.1:6379> zadd salary 100 zhangsan
(integer) 1
127.0.0.1:6379> zrangebyscore salary -inf +inf
1) "zhangsan"
2) "xiaohong"
3) "tao"
127.0.0.1:6379> zrevrange salary 0 -1
1) "tao"
2) "xiaohong"
3) "zhangsan"
127.0.0.1:6379> zrangebyscore salary -inf +inf withscores
1) "zhangsan"
2) "100"
3) "xiaohong"
4) "2500"
5) "tao"
6) "5000"
```



### zrem

```shell
127.0.0.1:6379> zrem salary tao
(integer) 1
```

### zcard

```shell
127.0.0.1:6379> zcard salary
(integer) 3
```

### zcount

```shell
127.0.0.1:6379> zcount salary 100 2500
(integer) 2
```

更多见官方文档

[中文官方文档](http://www.redis.cn/commands.html)



# Redis 三种特殊数据类型

## bitmaps

应用场景： 统计用户信息，活跃，不活跃；登录，未登录；

Bitmaps 位图，数据结构！都是操作二进制位来进行记录，就只有0和1两个状态！

```shell
# 记录打卡数据 周一到周五 1为正常 0为缺勤
127.0.0.1:6379> setbit sign 1 1
(integer) 0
127.0.0.1:6379> setbit sign 2 0
(integer) 0
127.0.0.1:6379> setbit sign 3 1
(integer) 0
127.0.0.1:6379> setbit sign 4 1
(integer) 0
127.0.0.1:6379> setbit sign 5 0
(integer) 0

#查看某一天是否打卡
127.0.0.1:6379> getbit sign 2
(integer) 0

# 统计打卡的天数
127.0.0.1:6379> bitcount sign
(integer) 3
```



## hyperloglogs  基数统计的算法

> 什么是基数？

A{1,3,5,7,8,7}

B{1,3,5,7,8}

基数(不重复的元素) = 5，可以接受误差。

优点：占用的内存固定，只需要12KB 内存！如果从内存角度比较的话Hyperloglog 首选！

应用场景：网页的UV(一个人访问一个网站多次，但还是算作一个人！)

传统的方式，set保存用户的id,然后就可以统计set 中元素的数量作为判断标准，这种方式比较麻烦，我们目的是为了计数，而不是保存用户id;

存在误差：0.81%

```shell
pfadd mykey a b c  # 创建第一组元素

pfcount mykey #统计元素的数量

pfadd mykey2 a d e # 创建第二组元素

pfmerge mykey3 mykey mykey2 # 合并两组 并集

pfcount mykey3 
5
```



## geospatial 地理位置

- [GEOADD](http://www.redis.cn/commands/geoadd.html)
- [GEODIST](http://www.redis.cn/commands/geodist.html)  应用场景：两个人的定位
- [GEOHASH](http://www.redis.cn/commands/geohash.html)
- [GEOPOS](http://www.redis.cn/commands/geopos.html)
- [GEORADIUS](http://www.redis.cn/commands/georadius.html)   应用场景：微信附近的人
- [GEORADIUSBYMEMBER](http://www.redis.cn/commands/georadiusbymember.html)

# 事务

Redis 事务本质：一组命令的集合！ 一个事务中的所有命令都会被序列化，在事务执行过程中，会按照顺序执行！

**Redis 事务没有隔离级别的概念！**

**所有的命令在事务中，并没有直接被执行！只有发起命令的时候才会执行！Exec**

**Redis 单条命令式保存原子性，但是事务不保证原子性！**

Redis 的事务:

- 开启事务（multi）
- 执行事务（......）
- 执行事务（exec）

## 正常执行事务exec

```shell
127.0.0.1:6379> multi
OK
127.0.0.1:6379> set k1 v1
QUEUED
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> get k2
QUEUED
127.0.0.1:6379> set k3 v3
QUEUED
127.0.0.1:6379> exec
1) OK
2) OK
3) "v2"
4) OK
```

## 放弃事务discard

```shell
127.0.0.1:6379> multi
OK
127.0.0.1:6379> set k1 v1
QUEUED
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> get k1
QUEUED
127.0.0.1:6379> discard
OK
127.0.0.1:6379> get k1
(nil)
127.0.0.1:6379> 

```

## 编译型异常（代码有问题，命令有错），事务中所有的命令都不会执行！

```shell
127.0.0.1:6379> multi
OK
127.0.0.1:6379> set k1 v1
QUEUED
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> set k3 v3
QUEUED
127.0.0.1:6379> getset k3
(error) ERR wrong number of arguments for 'getset' command
127.0.0.1:6379> set k4 v4
QUEUED
127.0.0.1:6379> exec
(error) EXECABORT Transaction discarded because of previous errors.
127.0.0.1:6379> get k4
(nil)
```



## 运行时异常(1/0) 如果事务队列中存在语法性错误，执行命令的时候，其他命令可以正常执行的

```shell
127.0.0.1:6379> set k1 "k"
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> incr k1
QUEUED
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> set k3 v3
QUEUED
127.0.0.1:6379> get k3
QUEUED
127.0.0.1:6379> exec
1) (error) ERR value is not an integer or out of range
2) OK
3) OK
4) "v3"

```

# # 乐观锁和悲观锁

## 乐观锁

- 很乐观，认为什么时候都不会出问题，所有不会上锁！更新数据的时候去判断一下，在此期间时候有人修改过这个数据，
- 获取version
- 更新的时候比较version

## 悲观锁

很悲观，认为什么时候都会出问题，无论做什么都会加锁！

## Redis监视测试

### 正常执行，没有出现问题

```shell
127.0.0.1:6379> set money 100
OK
127.0.0.1:6379> set out 0
OK
127.0.0.1:6379> watch money
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> decrby money 20
QUEUED
127.0.0.1:6379> incrby out 20
QUEUED
127.0.0.1:6379> exec
1) (integer) 80
2) (integer) 20
127.0.0.1:6379> 
```



### 出现问题（使用watch 可以当做乐观锁）



线程一 不执行事务

```shell
127.0.0.1:6379> set money 100
OK
127.0.0.1:6379> set out 10
OK
127.0.0.1:6379> watch money
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> decrby money 10
QUEUED
127.0.0.1:6379> incrby out 10
QUEUED
127.0.0.1:6379> 
```

线程二 插入线程一，修改money 值

```shell
127.0.0.1:6379> get money
"100"
127.0.0.1:6379> set money 200
OK
```

线程一提交失败

```shell
127.0.0.1:6379> set money 100
OK
127.0.0.1:6379> set out 10
OK
127.0.0.1:6379> watch money
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> decrby money 10
QUEUED
127.0.0.1:6379> incrby out 10
QUEUED
127.0.0.1:6379> exec
(nil)
```

## 解决方法

```shell
127.0.0.1:6379> unwatch #1.如果发现事务执行失败，就先解锁
OK
127.0.0.1:6379> watch money #2. 获取最新的值，再次监视，select version 
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> decrby money 10
QUEUED
127.0.0.1:6379> incrby out 10
QUEUED
127.0.0.1:6379> exec #.3比对监视的值是否发生了变化，如果没有变化，那么可以执行成功，如果变了就执行失败
1) (integer) 190
2) (integer) 20
127.0.0.1:6379> 
```

# Jedis

省略

# SpringBoot 整合 Redis 采坑

说明：在SpringBoot2.x 之后，原来使用的jedis 被替换了lettuce

jedis:采用的直连，多个线程操作的话，是不安全的，如果想要避免不安全的，使用jedis  pool 连接池！ BIO

lettuce: 采用netty，实例可以再多个线程中进行共享，不存在线程不安全的情况！可以减少线程数据，更像NIO



## 主要源码

```java
@Bean
    @ConditionalOnMissingBean(
        name = {"redisTemplate"}
    )
    public RedisTemplate<Object, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException {
        RedisTemplate<Object, Object> template = new RedisTemplate();
        template.setConnectionFactory(redisConnectionFactory);
        return template;
    }

    @Bean
    @ConditionalOnMissingBean
    public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException {
        StringRedisTemplate template = new StringRedisTemplate();
        template.setConnectionFactory(redisConnectionFactory);
        return template;
    }


```





## application.properties

springBoot2.x 版本以上一定要连 spring.redis.lettuce 

spring.redis.timeout=5000，可能会连接超时，可以调的大一些

```properties
# REDIS (RedisProperties)
# Redis数据库索引（默认为0）
spring.redis.database=0
# Redis服务器地址
spring.redis.host=192.168.0.101
# Redis服务器连接端口
spring.redis.port=6379
# 连接池最大连接数（使用负值表示没有限制）
spring.redis.lettuce.pool.max-active=8
# 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.lettuce.pool.max-wait=-1
# 连接池中的最大空闲连接
spring.redis.lettuce.pool.max-idle=8
# 连接池中的最小空闲连接
spring.redis.lettuce.pool.min-idle=0
# 连接超时时间（毫秒）
spring.redis.timeout=10000  
```



##  缺少commons-pool2包

缺包，或者是版本兼容问题，我之前用的是SpringBoot2.3 与commons-pool2  2.0版本也会提示控制台提示以下错误

```java
Caused by: java.lang.ClassNotFoundException: org.apache.commons.pool2.impl.GenericObjectPoolConf处理异常
```

```xml
<dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-pool2</artifactId>
            <version>2.8</version>
</dependency>
```



## 连接虚拟机上的Redis

(1)虚拟机上的redis.conf 文件

```bash
protected-mode no
bind 0.0.0.0
daemonize  yes
```

(2) 关闭虚拟机上的防火墙

```bash
 （centOS7） systemctl stop firewalld.service
```

(2) 本地cmd测试

```bash
ping 192.168.0.101

telnet 192.168.0.101 6379  #telnet ip 空格 端口号
```

![image-20200828070226198](https://gitee.com/claa/tuci/raw/master/img/image-20200828070226198.png)

## 测试代码

```java
package com.example.springboot.demo;

import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.data.redis.core.RedisTemplate;

@SpringBootTest
class DemoApplicationTests {

    @Autowired
    private RedisTemplate redisTemplate;
    @Test
    void contextLoads() {
       redisTemplate.opsForValue().set("mykey","www");
       System.out.println(redisTemplate.opsForValue().get("mykey"));

    }

}

```

**控制台成功输出“www”的结果**



# Redis 自定义RedisTemplate 以及RedisUtil 工具类

采用序列化的配置，避免出现乱码。

```java
@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate<String, Object> template = new RedisTemplate<String, Object>();
        template.setConnectionFactory(factory);
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper om = new ObjectMapper();
        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        om.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL);
        jackson2JsonRedisSerializer.setObjectMapper(om);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();

        // key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        // hash的key也采用String的序列化方式
        template.setHashKeySerializer(stringRedisSerializer);
        // value序列化方式采用jackson
        template.setValueSerializer(jackson2JsonRedisSerializer);
        // hash的value序列化方式采用jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);
        template.afterPropertiesSet();

        return template;
    }
}
```

```java
@Component
public class RedisUtils {

    @Autowired
    private RedisTemplate<String, Object> redisTemplate;

    // =============================common============================
    /**
     * 指定缓存失效时间
     * @param key  键
     * @param time 时间(秒)
     */
    public boolean expire(String key, long time) {
        try {
            if (time > 0) {
                redisTemplate.expire(key, time, TimeUnit.SECONDS);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 根据key 获取过期时间
     * @param key 键 不能为null
     * @return 时间(秒) 返回0代表为永久有效
     */
    public long getExpire(String key) {
        return redisTemplate.getExpire(key, TimeUnit.SECONDS);
    }


    /**
     * 判断key是否存在
     * @param key 键
     * @return true 存在 false不存在
     */
    public boolean hasKey(String key) {
        try {
            return redisTemplate.hasKey(key);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 删除缓存
     * @param key 可以传一个值 或多个
     */
    @SuppressWarnings("unchecked")
    public void del(String... key) {
        if (key != null && key.length > 0) {
            if (key.length == 1) {
                redisTemplate.delete(key[0]);
            } else {
                redisTemplate.delete(CollectionUtils.arrayToList(key));
            }
        }
    }


    // ============================String=============================

    /**
     * 普通缓存获取
     * @param key 键
     * @return 值
     */
    public Object get(String key) {
        return key == null ? null : redisTemplate.opsForValue().get(key);
    }

    /**
     * 普通缓存放入
     * @param key   键
     * @param value 值
     * @return true成功 false失败
     */

    public boolean set(String key, Object value) {
        try {
            redisTemplate.opsForValue().set(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 普通缓存放入并设置时间
     * @param key   键
     * @param value 值
     * @param time  时间(秒) time要大于0 如果time小于等于0 将设置无限期
     * @return true成功 false 失败
     */

    public boolean set(String key, Object value, long time) {
        try {
            if (time > 0) {
                redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);
            } else {
                set(key, value);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 递增
     * @param key   键
     * @param delta 要增加几(大于0)
     */
    public long incr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递增因子必须大于0");
        }
        return redisTemplate.opsForValue().increment(key, delta);
    }


    /**
     * 递减
     * @param key   键
     * @param delta 要减少几(小于0)
     */
    public long decr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递减因子必须大于0");
        }
        return redisTemplate.opsForValue().increment(key, -delta);
    }


    // ================================Map=================================

    /**
     * HashGet
     * @param key  键 不能为null
     * @param item 项 不能为null
     */
    public Object hget(String key, String item) {
        return redisTemplate.opsForHash().get(key, item);
    }

    /**
     * 获取hashKey对应的所有键值
     * @param key 键
     * @return 对应的多个键值
     */
    public Map<Object, Object> hmget(String key) {
        return redisTemplate.opsForHash().entries(key);
    }

    /**
     * HashSet
     * @param key 键
     * @param map 对应多个键值
     */
    public boolean hmset(String key, Map<String, Object> map) {
        try {
            redisTemplate.opsForHash().putAll(key, map);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * HashSet 并设置时间
     * @param key  键
     * @param map  对应多个键值
     * @param time 时间(秒)
     * @return true成功 false失败
     */
    public boolean hmset(String key, Map<String, Object> map, long time) {
        try {
            redisTemplate.opsForHash().putAll(key, map);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 向一张hash表中放入数据,如果不存在将创建
     *
     * @param key   键
     * @param item  项
     * @param value 值
     * @return true 成功 false失败
     */
    public boolean hset(String key, String item, Object value) {
        try {
            redisTemplate.opsForHash().put(key, item, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 向一张hash表中放入数据,如果不存在将创建
     *
     * @param key   键
     * @param item  项
     * @param value 值
     * @param time  时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间
     * @return true 成功 false失败
     */
    public boolean hset(String key, String item, Object value, long time) {
        try {
            redisTemplate.opsForHash().put(key, item, value);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 删除hash表中的值
     *
     * @param key  键 不能为null
     * @param item 项 可以使多个 不能为null
     */
    public void hdel(String key, Object... item) {
        redisTemplate.opsForHash().delete(key, item);
    }


    /**
     * 判断hash表中是否有该项的值
     *
     * @param key  键 不能为null
     * @param item 项 不能为null
     * @return true 存在 false不存在
     */
    public boolean hHasKey(String key, String item) {
        return redisTemplate.opsForHash().hasKey(key, item);
    }


    /**
     * hash递增 如果不存在,就会创建一个 并把新增后的值返回
     *
     * @param key  键
     * @param item 项
     * @param by   要增加几(大于0)
     */
    public double hincr(String key, String item, double by) {
        return redisTemplate.opsForHash().increment(key, item, by);
    }


    /**
     * hash递减
     *
     * @param key  键
     * @param item 项
     * @param by   要减少记(小于0)
     */
    public double hdecr(String key, String item, double by) {
        return redisTemplate.opsForHash().increment(key, item, -by);
    }


    // ============================set=============================

    /**
     * 根据key获取Set中的所有值
     * @param key 键
     */
    public Set<Object> sGet(String key) {
        try {
            return redisTemplate.opsForSet().members(key);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }


    /**
     * 根据value从一个set中查询,是否存在
     *
     * @param key   键
     * @param value 值
     * @return true 存在 false不存在
     */
    public boolean sHasKey(String key, Object value) {
        try {
            return redisTemplate.opsForSet().isMember(key, value);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 将数据放入set缓存
     *
     * @param key    键
     * @param values 值 可以是多个
     * @return 成功个数
     */
    public long sSet(String key, Object... values) {
        try {
            return redisTemplate.opsForSet().add(key, values);
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }


    /**
     * 将set数据放入缓存
     *
     * @param key    键
     * @param time   时间(秒)
     * @param values 值 可以是多个
     * @return 成功个数
     */
    public long sSetAndTime(String key, long time, Object... values) {
        try {
            Long count = redisTemplate.opsForSet().add(key, values);
            if (time > 0) {
                expire(key, time);
            }
            return count;
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }


    /**
     * 获取set缓存的长度
     *
     * @param key 键
     */
    public long sGetSetSize(String key) {
        try {
            return redisTemplate.opsForSet().size(key);
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }


    /**
     * 移除值为value的
     *
     * @param key    键
     * @param values 值 可以是多个
     * @return 移除的个数
     */

    public long setRemove(String key, Object... values) {
        try {
            Long count = redisTemplate.opsForSet().remove(key, values);
            return count;
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }

    // ===============================list=================================

    /**
     * 获取list缓存的内容
     *
     * @param key   键
     * @param start 开始
     * @param end   结束 0 到 -1代表所有值
     */
    public List<Object> lGet(String key, long start, long end) {
        try {
            return redisTemplate.opsForList().range(key, start, end);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }


    /**
     * 获取list缓存的长度
     *
     * @param key 键
     */
    public long lGetListSize(String key) {
        try {
            return redisTemplate.opsForList().size(key);
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }


    /**
     * 通过索引 获取list中的值
     *
     * @param key   键
     * @param index 索引 index>=0时， 0 表头，1 第二个元素，依次类推；index<0时，-1，表尾，-2倒数第二个元素，依次类推
     */
    public Object lGetIndex(String key, long index) {
        try {
            return redisTemplate.opsForList().index(key, index);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }


    /**
     * 将list放入缓存
     *
     * @param key   键
     * @param value 值
     */
    public boolean lSet(String key, Object value) {
        try {
            redisTemplate.opsForList().rightPush(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 将list放入缓存
     * @param key   键
     * @param value 值
     * @param time  时间(秒)
     */
    public boolean lSet(String key, Object value, long time) {
        try {
            redisTemplate.opsForList().rightPush(key, value);
            if (time > 0) {
                expire(key, time);
            }
                return true;

        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }

    }


    /**
     * 将list放入缓存
     *
     * @param key   键
     * @param value 值
     * @return
     */
    public boolean lSet(String key, List<Object> value) {
        try {
            redisTemplate.opsForList().rightPushAll(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }

    }


    /**
     * 将list放入缓存
     *
     * @param key   键
     * @param value 值
     * @param time  时间(秒)
     * @return
     */
    public boolean lSet(String key, List<Object> value, long time) {
        try {
            redisTemplate.opsForList().rightPushAll(key, value);
            if (time > 0) {
                expire(key, time);
            }
                return true;

        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 根据索引修改list中的某条数据
     *
     * @param key   键
     * @param index 索引
     * @param value 值
     * @return
     */

    public boolean lUpdateIndex(String key, long index, Object value) {
        try {
            redisTemplate.opsForList().set(key, index, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 移除N个值为value
     *
     * @param key   键
     * @param count 移除多少个
     * @param value 值
     * @return 移除的个数
     */

    public long lRemove(String key, long count, Object value) {
        try {
            Long remove = redisTemplate.opsForList().remove(key, count, value);
            return remove;
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }

    }
}
```

# Redis.conf文件详解

## 单位

![image-20200829095418635](https://gitee.com/claa/tuci/raw/master/img/image-20200829095418635.png)

1.配置文件unit 单位大小写不敏感

## 包含

![image-20200829095543672](https://gitee.com/claa/tuci/raw/master/img/image-20200829095543672.png)

## 网络  NETWORK

```bash
bind 127.0.0.1 #绑定的ip
protected-mode yes #保护模式
port 6379 #端口设置
```

## 通用 GENERAL

```bash
daemonize yes  # 以守护进程的方式运行，默认是no,我们需要自己开启为yes

pidfile /var/run/redis_6379.pid #如果以后台的方式运行，我们就需要指定一个pid文件

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
loglevel notice

logfile "" #日志的文件位置名

databases 16 #数据库的数量，默认是16 个数据库

always-show-logo yes # 是否总是显示logo
```

## 快照 SNAPSHOTTING

持久化，在规定的时间内，执行了多次操作，则会持久化到文件.rdb .aof

redis 是内存数据库，如果没有持久化，那么数据断电即失。

```bash
save 900 1  # 在900s内 如果至少1个key 进行了修改，我们即进行持久化操作

save 300 10 # 在300s内 如果至少1个key 进行了修改，我们即进行持久化操作

save 60 10000 # 在60s内 如果至少1个key 进行了修改，我们即进行持久化操作

stop-writes-on-bgsave-error yes #持久化如果出错，是否还需要继续工作！

rdbcompression yes #是否压缩rdb 文件，需要消耗一些cpu资源

rdbchecksum yes #保存rdb 文件的时候，进行错误的检查校验

dbfilename dump.rdb #保存数据的文件名 

rdb-del-sync-files no #在没有持久性的实例中删除复制使用的RDB文件
```

## 主从复制 REPLICATION

```bash
# replicaof <masterip> <masterport> #在从机上配置上主机的ip 和 port
```



## 安全 SECURITY

可以设置redis 的密码，默认是没有密码

```bash
config get requirepass ## 获取redis 的密码

config set requirepass "123456" # 设置redis的密码

auth 123456 # 登录
```

## 限制 CLIENTS

```bash
 maxclients 10000 # 设置能连接上redis的最大客户端的数量
 
 maxmemory <bytes> # redis 配置最大的内存容量
 
 maxmemory-policy noeviction #内存达到上限之后的处理策略
  
volatile-lru：采用最近使用最少的淘汰策略，Redis将回收那些超时的（仅仅是超时的）键值对，也就是它只淘汰那些超时的键值对。
allkeys-lru：采用最近最少使用的淘汰策略，Redis将对所有（不仅仅是超时的）的键值对采用最近最少使用的淘汰策略。
volatile-lfu：采用最近最不常用的淘汰策略，所谓最近最不常用，也就是一定时期内被访问次数最少的。Redis将回收超时的键值对。
allkeys-lfu：采用最近最不常用的淘汰策略，Redis将对所有的键值对采用最近最不常用的淘汰策略。
volatile-random：采用随机淘汰策略删除超时的键值对。
allkeys-random：采用随机淘汰策略删除所有的键值对，这个策略不常用。
volatile-ttl：采用删除存活时间最短的键值对策略。
noeviction：不淘汰任何键值对，当内存满时，如果进行读操作，例如get命令，它将正常工作，而做写操作，它将返回错误，也就是说，当Redis采用这个策略内存达到最大的时候，它就只能读不能写了。

Redis默认采用noeviction策略。
 
```



##  APPEND ONLY MODE aof 配置

```bash
appendonly no # 默认是不开启aof模式的，默认使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用！

appendfilename "appendonly.aof"  # 持久化的文件的名字

# appendfsync always  # 每次修改都会sync.消耗性能。
appendfsync everysec  #每次执行一次sync，可能会丢失这1s 的数据！
# appendfsync no      #不执行sync ,这个时候操作系统自己会同步数据，速度最快！
```



# Redis 持久化

## RDB

在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是快照，它恢复时将快照文件直接读到内存里。

![image-20200829104300957](https://gitee.com/claa/tuci/raw/master/img/image-20200829104300957.png)

Redis 会单独创建（fork） 一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。

RDB 保存的文件 dump.rdb

![image-20200829110740997](https://gitee.com/claa/tuci/raw/master/img/image-20200829110740997.png)



Redis.conf 文件中

```bash
save 900 1  # 在900s内 如果至少1个key 进行了修改，我们即进行持久化操作

save 300 10 # 在300s内 如果至少1个key 进行了修改，我们即进行持久化操作

save 60 10000 # 在60s内 如果至少1个key 进行了修改，我们即进行持久化操作
```

### 触发机制

1.save 的规则满足的情况下，会自动产生rdb 文件

2.执行flushall 命令，也会产生rdb 文件

3.退出redis ,也会产生rdb 文件

### 恢复文件

1，只需要将rdb文件放在我们的redis启动目录就可以，redis启动的时候会自动检查dump.rdb恢复其中的数据！

2.查看需要存放的位置

```bash
127.0.0.1:6379> config get dir
1) "dir"
2) "/usr/local/bin"
```

### 特点

大规模数据的恢复，且对数据恢复的完整性不是非常敏感。

 redis 意外宕机，最后一次持久化的数据会丢失。

fork进程的时候，会占有一定的内容空间。

## AOF

![image-20200829114104697](https://gitee.com/claa/tuci/raw/master/img/image-20200829114104697.png)

以日志的形式来记录每个写操作，将Redis 执行过的所有指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

AOF 保存的是appendonly.aof文件

Redis.conf 文件

```bash
appendonly no # 默认是不开启aof模式的，默认使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用！

appendfilename "appendonly.aof"  # 持久化的文件的名字

# appendfsync always  # 每次修改都会sync.消耗性能。
appendfsync everysec  #每次执行一次sync，可能会丢失这1s 的数据！
# appendfsync no      #不执行sync ,这个时候操作系统自己会同步数据，速度最快！
```

### 修复AOF文件

如果AOF 文件有错误，无法启动，需要修复这个AOF文件，修复工具：

```bash
redis-check-aof
```

如果文件正常，重启就可以直接恢复了。

### 特点

每一次修改都会同步；

每秒同步一次，可能会丢失一秒的数据；

从不同步，效率最高；

从数据文件来说，AOF比RDB大，修复速度以及运行效率都比较慢。

## 拓展

![image-20200829120349963](https://gitee.com/claa/tuci/raw/master/img/image-20200829120349963.png)

![image-20200829120502843](https://gitee.com/claa/tuci/raw/master/img/image-20200829120502843.png)

# Redis发布订阅

Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接受消息。微信、微博关注系统！

Redis 客户端可以订阅任意数量的频道。

**订阅/发布消息图** 

![image-20200829161754955](https://gitee.com/claa/tuci/raw/master/img/image-20200829161754955.png)



下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：

![img](https://www.runoob.com/wp-content/uploads/2014/11/pubsub1.png)

当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：

![img](https://www.runoob.com/wp-content/uploads/2014/11/pubsub2.png)



## Redis 发布订阅命令

下表列出了 redis 发布订阅常用命令：

| 序号 | 命令及描述                                                   |
| :--- | :----------------------------------------------------------- |
| 1    | [PSUBSCRIBE pattern [pattern ...\]](https://www.runoob.com/redis/pub-sub-psubscribe.html)  订阅一个或多个符合给定模式的频道。 |
| 2    | [PUBSUB subcommand [argument [argument ...\]]](https://www.runoob.com/redis/pub-sub-pubsub.html)  查看订阅与发布系统状态。 |
| 3    | [PUBLISH channel message](https://www.runoob.com/redis/pub-sub-publish.html)  将信息发送到指定的频道。 |
| 4    | [PUNSUBSCRIBE [pattern [pattern ...\]]](https://www.runoob.com/redis/pub-sub-punsubscribe.html)  退订所有给定模式的频道。 |
| 5    | [SUBSCRIBE channel [channel ...\]](https://www.runoob.com/redis/pub-sub-subscribe.html)  订阅给定的一个或多个频道的信息。 |
| 6    | [UNSUBSCRIBE [channel [channel ...\]]](https://www.runoob.com/redis/pub-sub-unsubscribe.html)  指退订给定的频道。 |

##  测试

订阅端：

```bash
127.0.0.1:6379> subscribe tao   # 订阅一个频道
Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "tao"
3) (integer) 1

# 等待读取推送的消息
1) "message"  #消息
2) "tao"      # 那个频道的消息
3) "hello,world" #消息的具体内容
```

发送端：

```bash
127.0.0.1:6379> publish tao "hello,world" # 发布者发布消息到频道
(integer) 1
```

## 原理

![image-20200829163613636](https://gitee.com/claa/tuci/raw/master/img/image-20200829163613636.png)



# Redis 主从复制

## 概念

主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master),后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。Master以写为主，Slave 以读为主。

**默认情况下，每台Redis 服务器都是主节点；**且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。

**主从复制的作用主要包括：**

1.数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。

2.故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上一种服务的冗余。

3.负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个节点分担读负载，可以大大提高Redis 服务器的并发容量。

4.高可用(集群)基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。



一般来说，要将Redis 运用于工程项目中，只使用一台Redis 是万万不能的(宕机)，原因如下：

1.从结构上，单个Redis 服务器会发生单点障碍，并且一台服务器需要处理所有的请求负载，压力较大；

2.从容量上，单个Redis 服务器内存容量有限，一般来说，单台Redis 最大使用内存不应该超过20G。

电商网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是“多读少写”。对于这种场景，就可以使用如下结构：

![image-20200829170909899](https://gitee.com/claa/tuci/raw/master/img/image-20200829170909899.png)



## 环境配置

```bash
127.0.0.1:6379> info replication  #查看当前库的信息
# Replication
role:master
connected_slaves:0
master_replid:94139a789f95b695496d076c6b0104cc17a3fb78
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
```

**复制3个配置文件，然后修改对应的信息**

**1.端口**

**2.pid名字**

**3.log文件名字**

**4.dump.rdb名字**

```bash
[root@localhost redisconfig]# cp redis.conf redis79.conf
[root@localhost redisconfig]# cp redis.conf redis80.conf
[root@localhost redisconfig]# cp redis.conf redis81.conf
[root@localhost redisconfig]# ls
redis79.conf  redis80.conf  redis81.conf  redis.conf
[root@localhost redisconfig]# vim redis79.conf
[root@localhost redisconfig]# vim redis80.conf
[root@localhost redisconfig]# vim redis81.conf
```

**集群环境搭建成功**：

```bash
[root@localhost ~]# ps -ef|grep redis
root       2500   2480  0 09:51 pts/0    00:00:00 vim redis.conf
root       2502   2480  0 09:53 pts/0    00:00:01 vim redis.conf
root       3026      1  0 17:32 ?        00:00:00 redis-server 0.0.0.0:6379
root       3032      1  0 17:33 ?        00:00:00 redis-server 0.0.0.0:6380
root       3038      1  0 17:34 ?        00:00:00 redis-server 0.0.0.0:6381
root       3044   3008 15 17:34 pts/3    00:00:00 grep --color=auto redis
```

## 一主二从

默认情况下，每台Redis服务器都是主节点；我们一般情况下只用配置从机就好。

一主(79,二从80.81)

```bash
127.0.0.1:6380> slaveof 127.0.0.1 6379
OK
127.0.0.1:6380> info replication
# Replication
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:4
master_sync_in_progress:0
slave_repl_offset:28
slave_priority:100
slave_read_only:1
connected_slaves:0
master_replid:e2d2c06f2adbe480413f5ea1d0c0411e0063ce7b
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:28
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:28
```

```bash
127.0.0.1:6381> slaveof 127.0.0.1 6379
OK
127.0.0.1:6381> info replication
# Replication
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:2
master_sync_in_progress:0
slave_repl_offset:224
slave_priority:100
slave_read_only:1
connected_slaves:0
master_replid:e2d2c06f2adbe480413f5ea1d0c0411e0063ce7b
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:224
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:211
repl_backlog_histlen:14
```

```bash
127.0.0.1:6379> info replication
# Replication
role:master
connected_slaves:2
slave0:ip=127.0.0.1,port=6380,state=online,offset=322,lag=0
slave1:ip=127.0.0.1,port=6381,state=online,offset=322,lag=0
master_replid:e2d2c06f2adbe480413f5ea1d0c0411e0063ce7b
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:322
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:322
```

**真实的从主配置应该在配置文件中配置，这样的话是永久的，我们这里使用的是命令，暂时的！**

```bash
# replicaof <masterip> <masterport> #在从机上配置上主机的ip 和 port
```



## 细节

**主机可以写，从机不能写只能读**

![image-20200829180637422](https://gitee.com/claa/tuci/raw/master/img/image-20200829180637422.png)

**主机断了，从机怎么手动可以变成主机**

```bash
slaveof no one
```

## 哨兵模式(自动选老大)

Redis 提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。

**其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis 实例**

![image-20200829182211769](https://gitee.com/claa/tuci/raw/master/img/image-20200829182211769.png)



**哨兵的作用**

(1)通过发送命令，让Redis 服务器返回监控其运行状态，包括主服务器和从服务器。

(2)当哨兵监测到master 宕机，会自动将salve 切换成master,然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换到主机。

**然而一个哨兵进程对Redis 服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会监控，这样就行成了多哨兵模式。**

![image-20200829182343173](https://gitee.com/claa/tuci/raw/master/img/image-20200829182343173.png)

![image-20200829183316151](https://gitee.com/claa/tuci/raw/master/img/image-20200829183316151.png)

**配置哨兵配置文件sentinel**

```bash
#sentinel monitor 被监控的名称 host port 1

sentinel monitor myredis 127.0.0.1 6379 1

# 后面的这个数字1,代表主机挂了，slave投票看让谁接替成为主机，票数最多的，就会成为主机！
```

**启动成功**

```
[root@localhost bin]# redis-sentinel redisconfig/sentinel.conf 
3134:X 29 Aug 2020 18:47:04.792 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
3134:X 29 Aug 2020 18:47:04.792 # Redis version=6.0.6, bits=64, commit=00000000, modified=0, pid=3134, just started
3134:X 29 Aug 2020 18:47:04.792 # Configuration loaded
3134:X 29 Aug 2020 18:47:04.793 * Increased maximum number of open files to 10032 (it was originally set to 1024).
                _._                                                  
           _.-``__ ''-._                                             
      _.-``    `.  `_.  ''-._           Redis 6.0.6 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._                                   
 (    '      ,       .-`  | `,    )     Running in sentinel mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 26379
 |    `-._   `._    /     _.-'    |     PID: 3134
  `-._    `-._  `-./  _.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |           http://redis.io        
  `-._    `-._`-.__.-'_.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |                                  
  `-._    `-._`-.__.-'_.-'    _.-'                                   
      `-._    `-.__.-'    _.-'                                       
          `-._        _.-'                                           
              `-.__.-'                                               

3134:X 29 Aug 2020 18:47:04.857 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
3134:X 29 Aug 2020 18:47:04.868 # Sentinel ID is 14291acb1675bc26fd767e174bb4299a8631188e
3134:X 29 Aug 2020 18:47:04.868 # +monitor master myredis 127.0.0.1 6379 quorum 1
3134:X 29 Aug 2020 18:47:04.889 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 6379
3134:X 29 Aug 2020 18:47:04.891 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 6379
```

## 哨兵模式的全部配置

![image-20200829190203416](https://gitee.com/claa/tuci/raw/master/img/image-20200829190203416.png)

![image-20200829190329875](https://gitee.com/claa/tuci/raw/master/img/image-20200829190329875.png)

![image-20200829190409537](https://gitee.com/claa/tuci/raw/master/img/image-20200829190409537.png)

![image-20200829190454254](https://gitee.com/claa/tuci/raw/master/img/image-20200829190454254.png)



# Redis 缓存穿透 和雪崩

## 缓冲穿透

### 概念

用户想要查询一个数据，发现redis 内存数据库没有，也就是缓冲没有命中，于是向持久层数据库查询，发现也没有，于是本次查询失败。当用户很多的时候，缓冲都没有命中，于是都去请求持久层数据库。这会给数据库造成很大的压力，这就相当于出现了缓冲穿透。

### 解决方案

**布隆过滤器**，是一种数据结构，对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃，从而避免了对底层存储系统的查询压力；

![image-20200829235708666](https://gitee.com/claa/tuci/raw/master/img/image-20200829235708666.png)

**缓冲空对象**

当存储层不命中，即使返回的空对象也将其缓冲起来，同时会设置一个过期时间，之后再访问这个数据将会从缓冲中获取，保护了后端数据源；

![image-20200830000128810](https://gitee.com/claa/tuci/raw/master/img/image-20200830000128810.png)

## 缓冲击穿

### 概念

缓冲击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓冲，直接请求数据库，就像在一个屏幕上凿开一个洞。

### 解决方案

**设置热点数据永不过期**

从缓存层面来看，没有设置过期时间，所以不会出现热点key 过期后产生的问题。

**加互斥锁**

分布式锁：使用分布式锁，保证对于每个key 同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁。

## 缓冲雪崩

### 概念

缓冲雪崩，是指在某一个时间段，缓冲集中过期失效。比如redis 宕机。

![image-20200830002515343](https://gitee.com/claa/tuci/raw/master/img/image-20200830002515343.png)

### 解决方案

异地多活 (多增加几台redis)

限流降级: 通过加锁或者队列来控制读数据库写缓冲的线程数量。

数据预热: 把可能大量访问的数据先加载到缓冲中，设置不同的过期时间，让缓冲的实现时间点尽量均匀。

